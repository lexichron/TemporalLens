{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Relations Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To extract causal relations between events using similarity semantics and COMET model.\n",
    "\n",
    "1. Loads COMET model from HuggingFace.\n",
    "2. Encodes events using SBERT to compare similarity.\n",
    "3. Generates possible effects of event A using COMET\n",
    "4. Measures similarity between Event B and COMET-generated effects.\n",
    "5. Decides if there's a causal relation based on a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "#with open(\"../data/events.json\", \"r\") as file:\n",
    "#    data = json.load(file)\n",
    "\n",
    "data = pd.read_parquet(\"../data/cluster_output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>event_summary</th>\n",
       "      <th>arguments</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Economic Warning</td>\n",
       "      <td>warn of inflation risks</td>\n",
       "      <td>Federal Reserve officials warned that the Trum...</td>\n",
       "      <td>{'agent': 'Federal Reserve officials', 'cause'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trade Policy</td>\n",
       "      <td>slapped tariffs</td>\n",
       "      <td>President Trump announced new tariffs on the t...</td>\n",
       "      <td>{'agent': 'President Trump', 'cause': 'Trump a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Diplomatic Agreement</td>\n",
       "      <td>suspending the tariffs</td>\n",
       "      <td>Trump agreed to suspend tariffs on Mexico and ...</td>\n",
       "      <td>{'agent': 'President Trump', 'cause': 'Agreeme...</td>\n",
       "      <td>[{'description': 'Suspensions were a response ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Economic Analysis</td>\n",
       "      <td>will push up inflation and depress growth</td>\n",
       "      <td>Economists predict the new tariffs will increa...</td>\n",
       "      <td>{'agent': 'Economists', 'cause': 'Implementati...</td>\n",
       "      <td>[{'description': 'Price increases and growth d...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Monetary Policy</td>\n",
       "      <td>held policy rate steady</td>\n",
       "      <td>The Federal Reserve decided to keep interest r...</td>\n",
       "      <td>{'agent': 'Federal Reserve', 'cause': 'Uncerta...</td>\n",
       "      <td>[{'description': 'Tariff-induced economic unce...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            event_type                                    trigger  \\\n",
       "0         0      Economic Warning                    warn of inflation risks   \n",
       "1         1          Trade Policy                            slapped tariffs   \n",
       "2         2  Diplomatic Agreement                     suspending the tariffs   \n",
       "3         3     Economic Analysis  will push up inflation and depress growth   \n",
       "4         4       Monetary Policy                    held policy rate steady   \n",
       "\n",
       "                                       event_summary  \\\n",
       "0  Federal Reserve officials warned that the Trum...   \n",
       "1  President Trump announced new tariffs on the t...   \n",
       "2  Trump agreed to suspend tariffs on Mexico and ...   \n",
       "3  Economists predict the new tariffs will increa...   \n",
       "4  The Federal Reserve decided to keep interest r...   \n",
       "\n",
       "                                           arguments  \\\n",
       "0  {'agent': 'Federal Reserve officials', 'cause'...   \n",
       "1  {'agent': 'President Trump', 'cause': 'Trump a...   \n",
       "2  {'agent': 'President Trump', 'cause': 'Agreeme...   \n",
       "3  {'agent': 'Economists', 'cause': 'Implementati...   \n",
       "4  {'agent': 'Federal Reserve', 'cause': 'Uncerta...   \n",
       "\n",
       "                                        dependencies  cluster_id  \n",
       "0                                                 []           0  \n",
       "1                                                 []         219  \n",
       "2  [{'description': 'Suspensions were a response ...           2  \n",
       "3  [{'description': 'Price increases and growth d...           3  \n",
       "4  [{'description': 'Tariff-induced economic unce...           4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique clusters\n",
    "data[\"cluster_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update the dependencies link (link to cluster id instead of event_id)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build event_id to cluster id mapping\n",
    "event_to_cluster = dict(zip(data[\"event_id\"], data[\"cluster_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dependencies for a single event\n",
    "def update_dependencies_to_cluster(dependencies, event_to_cluster):\n",
    "    \"\"\"Replace event_id in dependencies to corresponding cluster_id\"\"\"\n",
    "    updated_deps = []\n",
    "    for dep in dependencies:\n",
    "        target_event_id = dep[\"event_id\"]\n",
    "        # lookup cluster_id\n",
    "        cluster_id = event_to_cluster.get(target_event_id, None)\n",
    "        if cluster_id is not None:\n",
    "            updated_dep = dep.copy()\n",
    "            updated_dep[\"event_id\"] = cluster_id\n",
    "            updated_deps.append(updated_dep)\n",
    "\n",
    "    return updated_deps\n",
    "\n",
    "# apply dependencies updating row wise\n",
    "data[\"dependencies\"] = data[\"dependencies\"].apply(lambda deps: update_dependencies_to_cluster(deps, event_to_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate dependencies\n",
    "def deduplicate_dependencies(dependencies):\n",
    "    \"\"\"Remove duplicate dependencies pointing to the same cluster_id\"\"\"\n",
    "    seen = set()\n",
    "    unique_deps = []\n",
    "    for dep in dependencies:\n",
    "        cid = dep[\"event_id\"]\n",
    "        if cid not in seen:\n",
    "            unique_deps.append(dep)\n",
    "            seen.add(cid)\n",
    "    return unique_deps\n",
    "\n",
    "data[\"dependencies\"] = data[\"dependencies\"].apply(deduplicate_dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter to get top 100 clusters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 100 clusters\n",
    "n = 1000\n",
    "top_clusters = data[\"cluster_id\"].value_counts().index.tolist()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only retain top 100 clusters\n",
    "data_top = data[data[\"cluster_id\"].isin(top_clusters)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each event in the top 100 cluster, retain the event with the longest trigger\n",
    "data_top[\"trigger_len\"] = data_top[\"trigger\"].apply(lambda x: len(x.split()))\n",
    "data_top[\"summary_len\"] = data_top[\"event_summary\"].apply(lambda x: len(x.split()))\n",
    "data_top = data_top.sort_values([\"cluster_id\", \"trigger_len\", \"summary_len\"], ascending=[True, False, False])\n",
    "\n",
    "# remove duplicates\n",
    "data_top_nodup = data_top.drop_duplicates(subset=[\"cluster_id\"], keep=\"first\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Cluster-Level Dependencies (based on `dependencies` field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cluster_dependency_edges(rep_event_df):\n",
    "    \"\"\"Extract dependency edges between clusters using representative events\"\"\"\n",
    "    dependency_edges = []\n",
    "    rel_type_list = [\"INFLUENCED\", \"TRIGGERED\", \"RELATED_TO\", \"RESPONSE_TO\"]\n",
    "\n",
    "    # Precompute lookup for efficiency\n",
    "    cluster_to_event = rep_event_df.set_index(\"cluster_id\").to_dict('index')\n",
    "\n",
    "    for idx, row in rep_event_df.iterrows():\n",
    "        source_cluster_id = row[\"cluster_id\"]\n",
    "        source_event_id = row[\"event_id\"]\n",
    "        source_trigger = row[\"trigger\"]\n",
    "        source_summary = row[\"event_summary\"]\n",
    "\n",
    "        for dep in row.get(\"dependencies\", []):  # Safe access\n",
    "            target_cluster_id = dep[\"event_id\"]\n",
    "            relation_type = dep[\"relation_type\"]\n",
    "            description = dep[\"description\"]\n",
    "\n",
    "            # Skip if invalid or self-loop\n",
    "            if target_cluster_id is None or source_cluster_id == target_cluster_id:\n",
    "                continue\n",
    "\n",
    "            target_row = cluster_to_event.get(target_cluster_id, None)\n",
    "            if target_row is None:\n",
    "                continue  # If target cluster not represented\n",
    "\n",
    "            target_trigger = target_row[\"trigger\"]\n",
    "            target_summary = target_row[\"event_summary\"]\n",
    "\n",
    "            # Build edge if relation is recognized\n",
    "            if relation_type == \"RESPONSE_TO\":\n",
    "                edge = {\n",
    "                    # Flip the source and target\n",
    "                    \"source_cluster_id\": target_cluster_id,\n",
    "                    \"target_cluster_id\": source_cluster_id,\n",
    "                    \"relation_type\": \"causes\",\n",
    "                    \"description\": description,\n",
    "                    \"source_trigger\": target_trigger,\n",
    "                    \"source_summary\": target_summary,\n",
    "                    \"target_trigger\": source_trigger,\n",
    "                    \"target_summary\": source_summary\n",
    "                }\n",
    "                dependency_edges.append(edge)\n",
    "            elif relation_type in rel_type_list:\n",
    "                edge = {\n",
    "                    \"source_cluster_id\": source_cluster_id,\n",
    "                    \"target_cluster_id\": target_cluster_id,\n",
    "                    \"relation_type\": \"causes\" if relation_type in [\"INFLUENCED\", \"TRIGGERED\"] else \"related_to\",\n",
    "                    \"description\": description,\n",
    "                    \"source_trigger\": source_trigger,\n",
    "                    \"source_summary\": source_summary,\n",
    "                    \"target_trigger\": target_trigger,\n",
    "                    \"target_summary\": target_summary\n",
    "                }\n",
    "                dependency_edges.append(edge)\n",
    "\n",
    "    print(f\"Extracted {len(dependency_edges)} cluster-level dependency edges.\")\n",
    "    return dependency_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 82 cluster-level dependency edges.\n"
     ]
    }
   ],
   "source": [
    "# extract cluster-level dependencies\n",
    "cluster_dependencies_edges = extract_cluster_dependency_edges(data_top_nodup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load COMET model\n",
    "comet_model_name = \"mismayil/comet-bart-ai2\"\n",
    "comet_tokenizer = AutoTokenizer.from_pretrained(comet_model_name)\n",
    "comet_model = AutoModelForSeq2SeqLM.from_pretrained(comet_model_name)\n",
    "\n",
    "# Load SBERT for semantic similarity\n",
    "sbert_model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Fast Lookup for Events**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from cluster_id to representative event\n",
    "cluster_to_event = data_top_nodup.set_index('cluster_id').to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_links = set()\n",
    "\n",
    "for edge in cluster_dependencies_edges:\n",
    "    source_cluster_id = edge['source_cluster_id']\n",
    "    target_cluster_id = edge['target_cluster_id']\n",
    "    # Add (source, target)\n",
    "    existing_links.add((source_cluster_id, target_cluster_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comet_relations(event_text, num_return_sequences=3, max_length=50):\n",
    "    relation_prompts = {'xEffect': f\"{event_text} xEffect\", 'isAfter': f\"{event_text} isAfter\"}\n",
    "    relation_results = {}\n",
    "    for relation, prompt in relation_prompts.items():\n",
    "        inputs = comet_tokenizer([prompt], return_tensors='pt')\n",
    "        outputs = comet_model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            do_sample=True,\n",
    "            temperature=0.5,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )\n",
    "        results = [comet_tokenizer.decode(output, skip_special_tokens=True).strip() for output in outputs]\n",
    "        relation_results[relation] = results\n",
    "    return relation_results\n",
    "\n",
    "# SBERT Similarity\n",
    "def sbert_similarity(text1, text2):\n",
    "    emb1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n",
    "\n",
    "def infer_cluster_links_with_comet_sbert(cluster_to_event, existing_links, similarity_threshold=0.7):\n",
    "    \"\"\"Link cluster representative events using COMET + SBERT, skipping existing links\"\"\"\n",
    "    cluster_ids = list(cluster_to_event.keys())\n",
    "    n = len(cluster_ids)\n",
    "    inferred_edges = []\n",
    "\n",
    "    for i in tqdm(range(n), desc=\"Linking clusters with COMET + SBERT\"):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue  # Skip self-pairs\n",
    "\n",
    "            source_cluster_id = cluster_ids[i]\n",
    "            target_cluster_id = cluster_ids[j]\n",
    "\n",
    "            # Skip if already linked\n",
    "            if (source_cluster_id, target_cluster_id) in existing_links or (target_cluster_id, source_cluster_id) in existing_links:\n",
    "                continue\n",
    "\n",
    "            event_a = cluster_to_event[source_cluster_id]\n",
    "            event_b = cluster_to_event[target_cluster_id]\n",
    "\n",
    "            # Run COMET on source event\n",
    "            comet_relations = generate_comet_relations(event_a['event_summary'])\n",
    "            comet_results = []\n",
    "\n",
    "            for rel_type in ['xEffect', 'isAfter']:\n",
    "                for effect in comet_relations[rel_type]:\n",
    "                    sim_score = sbert_similarity(effect, event_b['event_summary'])\n",
    "                    comet_results.append((sim_score, rel_type, effect))\n",
    "\n",
    "            # -------- Select best match -------- #\n",
    "            if comet_results:\n",
    "                comet_effects_score, best_comet_type, best_comet_effect = max(comet_results, key=lambda x: x[0])\n",
    "            else:\n",
    "                comet_effects_score, best_comet_type, best_comet_effect = 0.0, None, None\n",
    "\n",
    "            # -------- Save link if above threshold -------- #\n",
    "            if comet_effects_score >= similarity_threshold:\n",
    "                relation_type = \"causes\" if best_comet_type == 'xEffect' else \"happens_before\"\n",
    "                explanation = (\n",
    "                    f\"Event '{event_a['trigger']}' {relation_type} Event '{event_b['trigger']}' \"\n",
    "                    f\"via COMET {best_comet_type}: '{best_comet_effect}'.\"\n",
    "                )\n",
    "\n",
    "                inferred_edge = {\n",
    "                    \"source_cluster_id\": source_cluster_id,\n",
    "                    \"target_cluster_id\": target_cluster_id,\n",
    "                    \"relation_type\": relation_type,\n",
    "                    \"confidence_score\": comet_effects_score,\n",
    "                    \"explanation\": explanation,\n",
    "                    \"source_trigger\": event_a['trigger'],\n",
    "                    \"source_summary\": event_a['event_summary'],\n",
    "                    \"target_trigger\": event_b['trigger'],\n",
    "                    \"target_summary\": event_b['event_summary'],\n",
    "                    \"evidence_type\": f\"comet_{best_comet_type}\"\n",
    "                }\n",
    "                inferred_edges.append(inferred_edge)\n",
    "\n",
    "    print(f\"Inferred {len(inferred_edges)} new relations using COMET + SBERT.\")\n",
    "    return inferred_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_comet_sbert_embeddings(rep_event_df):\n",
    "    \"\"\"Precompute COMET relations and SBERT embeddings for all representative events.\"\"\"\n",
    "    cache = {}\n",
    "\n",
    "    for idx, row in tqdm(rep_event_df.iterrows(), total=len(rep_event_df), desc=\"Precomputing COMET+SBERT\"):\n",
    "        cluster_id = row['cluster_id']\n",
    "        event_summary = row['event_summary']\n",
    "\n",
    "        # Generate COMET relations \n",
    "        comet_relations = generate_comet_relations(event_summary)\n",
    "\n",
    "        # Compute SBERT embeddings for COMET outputs\n",
    "        comet_embeddings = {\n",
    "            rel_type: sbert_model.encode(effects, convert_to_tensor=True).cpu().tolist()\n",
    "            for rel_type, effects in comet_relations.items()\n",
    "        }\n",
    "\n",
    "        # Compute SBERT embedding for event_summary \n",
    "        summary_embedding = sbert_model.encode(event_summary, convert_to_tensor=True).cpu().tolist()\n",
    "\n",
    "        # Cache all \n",
    "        cache[cluster_id] = {\n",
    "            'comet_relations': comet_relations,\n",
    "            'comet_embeddings': comet_embeddings,\n",
    "            'summary_embedding': summary_embedding,\n",
    "            'trigger': row['trigger'],\n",
    "            'event_summary': row['event_summary']\n",
    "        }\n",
    "\n",
    "    print(f\"Precomputed COMET and SBERT embeddings for {len(rep_event_df)} events.\")\n",
    "    return cache\n",
    "\n",
    "def save_comet_sbert_cache(cache, save_path='../data/cluste/comet_sbert_cache.jsonl'):\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for cluster_id, data in cache.items():\n",
    "            json.dump({cluster_id: data}, f)\n",
    "            f.write('\\n')\n",
    "    print(f\"Saved COMET + SBERT cache to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing COMET+SBERT: 100%|██████████| 1000/1000 [28:10<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed COMET and SBERT embeddings for 1000 events.\n",
      "Saved COMET + SBERT cache to ../data/cluster/comet_sbert_cache.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Precompute and save COMET+SBERT embeddings\n",
    "cache = precompute_comet_sbert_embeddings(data_top_nodup)\n",
    "save_comet_sbert_cache(cache, save_path='../data/cluster/comet_sbert_cache.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Cached Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_comet_sbert_cache(load_path='../data/cluster/comet_sbert_cache.jsonl'):\n",
    "    cache = {}\n",
    "    with open(load_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            cluster_id, data = next(iter(entry.items()))\n",
    "            cache[int(cluster_id)] = {\n",
    "                'comet_relations': data['comet_relations'],\n",
    "                'comet_embeddings': {k: torch.tensor(v) for k, v in data['comet_embeddings'].items()},\n",
    "                'summary_embedding': torch.tensor(data['summary_embedding']),\n",
    "                'trigger': data['trigger'],\n",
    "                'event_summary': data['event_summary']\n",
    "            }\n",
    "    print(f\"Loaded COMET + SBERT cache for {len(cache)} clusters.\")\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded COMET + SBERT cache for 1000 clusters.\n"
     ]
    }
   ],
   "source": [
    "# Load the cached embeddings when needed\n",
    "cache_loaded = load_comet_sbert_cache('../data/cluster/comet_sbert_cache.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairwise comparison to infer relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_links_with_cached_embeddings(cache, existing_links, similarity_threshold=0.7):\n",
    "    \"\"\"Pairwise linking using precomputed COMET + SBERT embeddings.\"\"\"\n",
    "    cluster_ids = list(cache.keys())\n",
    "    n = len(cluster_ids)\n",
    "    inferred_edges = []\n",
    "\n",
    "    for i in tqdm(range(n), desc=\"Linking clusters using cached embeddings\"):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue  # Skip self-pair\n",
    "\n",
    "            source_cluster_id = cluster_ids[i]\n",
    "            target_cluster_id = cluster_ids[j]\n",
    "\n",
    "            # Skip existing dependency links\n",
    "            if (source_cluster_id, target_cluster_id) in existing_links or (target_cluster_id, source_cluster_id) in existing_links:\n",
    "                continue\n",
    "\n",
    "            source_data = cache[source_cluster_id]\n",
    "            target_data = cache[target_cluster_id]\n",
    "\n",
    "            target_summary_embedding = target_data['summary_embedding']\n",
    "\n",
    "            best_score, best_relation, best_effect = 0.0, None, None\n",
    "\n",
    "            for rel_type in ['xEffect', 'isAfter']:\n",
    "                effect_embeddings = source_data['comet_embeddings'][rel_type]  # Tensor\n",
    "                similarities = util.cos_sim(target_summary_embedding, effect_embeddings).squeeze(0)\n",
    "                max_sim = torch.max(similarities).item()\n",
    "\n",
    "                if max_sim > best_score:\n",
    "                    best_score = max_sim\n",
    "                    best_relation = 'causes' if rel_type == 'xEffect' else 'happens_before'\n",
    "                    best_idx = torch.argmax(similarities).item()\n",
    "                    best_effect = source_data['comet_relations'][rel_type][best_idx]\n",
    "\n",
    "            if best_score >= similarity_threshold:\n",
    "                explanation = (\n",
    "                    f\"Event '{source_data['trigger']}' {best_relation} Event '{target_data['trigger']}' \"\n",
    "                    f\"via COMET: '{best_effect}'\"\n",
    "                )\n",
    "                inferred_edges.append({\n",
    "                    \"source_cluster_id\": source_cluster_id,\n",
    "                    \"target_cluster_id\": target_cluster_id,\n",
    "                    \"relation_type\": best_relation,\n",
    "                    \"confidence_score\": best_score,\n",
    "                    \"explanation\": explanation,\n",
    "                    \"source_trigger\": source_data['trigger'],\n",
    "                    \"source_summary\": source_data['event_summary'],\n",
    "                    \"target_trigger\": target_data['trigger'],\n",
    "                    \"target_summary\": target_data['event_summary'],\n",
    "                    \"evidence_type\": f\"comet_{best_relation}\"\n",
    "                })\n",
    "\n",
    "    print(f\"Inferred {len(inferred_edges)} new cluster-level links.\")\n",
    "    return inferred_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking clusters using cached embeddings: 100%|██████████| 1000/1000 [01:08<00:00, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred 359 new cluster-level links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference on cluster pairs, avoiding existing links\n",
    "comet_sbert_edges = infer_cluster_links_with_cached_embeddings(\n",
    "    cache_loaded,\n",
    "    existing_links,\n",
    "    similarity_threshold=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 82 dependency edges and 359 COMET/SBERT edges.\n",
      "Total combined edges: 441\n"
     ]
    }
   ],
   "source": [
    "# Combine both lists of edges\n",
    "combined_edges = cluster_dependencies_edges + comet_sbert_edges\n",
    "\n",
    "print(f\"Combined {len(cluster_dependencies_edges)} dependency edges and {len(comet_sbert_edges)} COMET/SBERT edges.\")\n",
    "print(f\"Total combined edges: {len(combined_edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_edges(edges, save_path='../data/cluster/combined_cluster_edges.jsonl'):\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for edge in edges:\n",
    "            json.dump(edge, f)\n",
    "            f.write('\\n')\n",
    "    print(f\"Saved {len(edges)} combined edges to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 441 combined edges to ../data/cluster/combined_cluster_edges.jsonl\n"
     ]
    }
   ],
   "source": [
    "# save the edges\n",
    "save_combined_edges(combined_edges, save_path='../data/cluster/combined_cluster_edges.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_cluster_id': 85,\n",
       "  'target_cluster_id': 198,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7020261287689209,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'imposed tariffs' via COMET: 'US President Donald Trump orders tariffs on products from Canada and China'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'imposed tariffs',\n",
       "  'target_summary': 'US President Donald Trump imposed tariffs on China and has considered similar measures against Taiwanese semiconductors.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 272,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7403940558433533,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'threatened to slap a 60 per cent flat fee on Chinese goods' via COMET: 'US president threatens to impose tariffs'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'threatened to slap a 60 per cent flat fee on Chinese goods',\n",
       "  'target_summary': 'President-elect Trump threatened to impose a substantial tariff on Chinese goods, prompting concerns about a potential second trade war with China.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 5089,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7200663685798645,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'impose an additional 10 per cent tariff' via COMET: 'US President Donald Trump orders tariffs on products from Canada and China'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'impose an additional 10 per cent tariff',\n",
       "  'target_summary': \"President-elect Donald Trump announced plans to impose an additional 10% tariff on Chinese goods, contingent on Beijing's efforts to curb fentanyl trafficking.\",\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 5442,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7504361271858215,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'threaten even more harsh trade tariffs' via COMET: 'US president threatens to impose tariffs'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'threaten even more harsh trade tariffs',\n",
       "  'target_summary': 'US President-elect Donald Trump threatened to impose more severe trade tariffs, affecting market dynamics and international trade relations.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 6083,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7208598256111145,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'threatened to impose a 100 per cent tariff' via COMET: 'US president threatens to impose tariffs'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'threatened to impose a 100 per cent tariff',\n",
       "  'target_summary': 'President-elect Donald Trump threatened to impose a 100% tariff on Brics countries if they undercut the US dollar.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 6406,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7155704498291016,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'impose a 10 per cent tariff on Chinese goods' via COMET: 'US President Donald Trump orders tariffs on products from Canada and China'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'impose a 10 per cent tariff on Chinese goods',\n",
       "  'target_summary': 'Donald Trump announced plans to impose a 10% tariff on Chinese goods to pressure Beijing to reduce the flow of Chinese-made chemicals contributing to the opioid crisis in the US.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 6624,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7542266845703125,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event '25 per cent tariff on all products from Mexico and Canada' via COMET: 'US President Donald Trump orders tariffs on products from Canada and China'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': '25 per cent tariff on all products from Mexico and Canada',\n",
       "  'target_summary': 'Donald Trump pledged a 25 per cent tariff on all products from Mexico and Canada due to immigration and drug trade concerns.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 85,\n",
       "  'target_cluster_id': 12270,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7194039821624756,\n",
       "  'explanation': \"Event 'sweeping tariffs on goods' happens_before Event 'impose punishing tariffs' via COMET: 'US President Donald Trump orders tariffs on products from Canada and China'\",\n",
       "  'source_trigger': 'sweeping tariffs on goods',\n",
       "  'source_summary': 'US President Donald Trump ordered sweeping tariffs on goods from Mexico, Canada, and China to control illegal immigration and fentanyl flow into the US.',\n",
       "  'target_trigger': 'impose punishing tariffs',\n",
       "  'target_summary': 'Donald Trump reiterated his pledge to impose severe tariffs on China as a strategy to bolster US manufacturing.',\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 196,\n",
       "  'target_cluster_id': 5613,\n",
       "  'relation_type': 'happens_before',\n",
       "  'confidence_score': 0.7422114610671997,\n",
       "  'explanation': \"Event 'choose dialogue over confrontation' happens_before Event 'spoke with House Speaker Mike Johnson' via COMET: 'President Lai Ching-te has a meeting with the Chinese leadership'\",\n",
       "  'source_trigger': 'choose dialogue over confrontation',\n",
       "  'source_summary': 'President Lai Ching-te called for dialogue and cooperation between Taiwan and China, emphasizing equality and dignity.',\n",
       "  'target_trigger': 'spoke with House Speaker Mike Johnson',\n",
       "  'target_summary': \"Taiwan President Lai Ching-te spoke with US House Speaker Mike Johnson and other US congressional leaders during his visit to the Pacific, amidst China's warning about crossing their 'red lines.'\",\n",
       "  'evidence_type': 'comet_happens_before'},\n",
       " {'source_cluster_id': 198,\n",
       "  'target_cluster_id': 5089,\n",
       "  'relation_type': 'causes',\n",
       "  'confidence_score': 0.7009719610214233,\n",
       "  'explanation': \"Event 'imposed tariffs' causes Event 'impose an additional 10 per cent tariff' via COMET: 'US imposes tariffs on Chinese'\",\n",
       "  'source_trigger': 'imposed tariffs',\n",
       "  'source_summary': 'US President Donald Trump imposed tariffs on China and has considered similar measures against Taiwanese semiconductors.',\n",
       "  'target_trigger': 'impose an additional 10 per cent tariff',\n",
       "  'target_summary': \"President-elect Donald Trump announced plans to impose an additional 10% tariff on Chinese goods, contingent on Beijing's efforts to curb fentanyl trafficking.\",\n",
       "  'evidence_type': 'comet_causes'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comet_sbert_edges[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
